---
title: "Risco de Crédito: Como uma Melhor Seleção de Variáveis Pode Ampliar a Eficácia das Previsões"
author: "Rafael Bicudo Rosa"
date: "24 de julho de 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Como a seleção de variáveis pode aumentar a eficácia de um modelo

O objetivo deste trabalho é usar dados sobre análises de crédito realizadas na Alemanha, executar uma análise exploratória, construir uma série de modelos de classificação baseados nessa, observar como a melhor seleção de variaveis afeta a performance e escolher o mais preciso.

Os dados incluem 1000 observações de concessão de crédito, cada uma com 21 variáveis, sendo a última a classificação do solicitante (bom ou mau pagador), e as restantes características qualitativas e quantitativas sobre esses mesmos. Todas as informacões foram retiradas do repositório online da Universidade de Irvine, Califórnia (https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data), assim como uma melhor explicação do significado das variáveis.


## Etapa 1 - Coleta dos Dados

Assim como descrito acima, os dados serão retirados de um repositório online contendo a base em si no
formato table, e as informações de cada uma das características. Em seguida, as variáveis serão nomeadas e, por fim, ter-se-á a primeira visão do dataframe.


```{r coleta}
## Obtencao dos dados

# Carrega o dataset antes da transformacao
german_credit_l <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'
Credit <- read.table(german_credit_l)

# Nome das variaveis
names(Credit) <- c('CheckingAcctStat', 'Duration', 'CreditHistory', 'Purpose', 'CreditAmount', 
                   'SavingsBonds', 'Employment', 'InstallmentRatePecnt', 'SexAndStatus', 
                   'OtherDetorsGuarantors', 'PresentResidenceTime', 'Property', 'Age', 
                   'OtherInstallments', 'Housing', 'ExistingCreditsAtBank', 'Job', 'NumberDependents', 
                   'Telephone', 'ForeignWorker', 'CreditStatus')

# Analise do dataframe
str(Credit)
summary(Credit)

```


## Etapa 2 - Limpeza e Preparação dos dados

A partir do demonstrado acima, vê-se a existência de alguns pontos de atenção: a diferenca de grandezas entre as variáveis quantitativas, e algumas variáveis qualitativas como numéricas. Ambos podem levar a viéses ruins ou inconsistências em modelos preditivos, portanto se segue a uma etapa de ajustamento dos dados.

```{r normalizando}
## Data Cleaning

# Definicao variavel de interesse 
Credit[, 'CreditStatus'] <- factor(Credit[, 'CreditStatus'], labels = c('Good', 'Bad'))

# Funcao para automatizar "fatorizacao" das variaveis
to.factor <- function(df, features) {
  for (feature in features) {
    df[[feature]] <- as.factor(df[[feature]])
  }
  return(df)
}

# Criacao do string vector das variaveis a  serem fatorizadas e sua fatorizacao
categorical_vars <- c('CheckingAcctStat', 'CreditHistory', 'Purpose', 
                     'SavingsBonds', 'Employment', 'InstallmentRatePecnt', 'SexAndStatus', 
                     'OtherDetorsGuarantors', 'PresentResidenceTime', 'Property',  
                     'OtherInstallments', 'Housing', 'ExistingCreditsAtBank', 'Job', 'NumberDependents', 
                     'Telephone', 'ForeignWorker', 'CreditStatus')

Credit <- to.factor(Credit, categorical_vars)

# Funcao para automatizar normalizacao
scale.features <- function(df, variables){
  for (variable in variables){
    df[[variable]] <- scale(df[[variable]], center=T, scale=T)
  }
  return(df)
}

# Normalizacao das variaveis
numeric_vars <- c("Duration", "Age", "CreditAmount")
scale_Credit <- scale.features(Credit, numeric_vars)

```


## Etapa 3 - Dividindo os dados em treino e teste

Com a preparacao dos dados concluída, pode-se prosseguir a separação dos dados entre treino, para modelagem e exploração, e teste, para validação da aprendizagem.

```{r treinamento}
# Carregando pacotes necessarios
library(caret)

# Separacao dos Sets de Treino e Teste
set.seed(666)
sample <- createDataPartition(scale_Credit$CreditStatus, times = 1, list = F, p = .6)
train_sample <- scale_Credit[sample, ]
test_sample <- scale_Credit[-sample, ]

```


## Etapa 4 - Selecao das variaveis

Com todas as transformações concluídas, segue-se para a seleção das variáveis mais explicativas. Para executar a tarefa, foi criada uma função para aplicar o método de seleção recursiva usando "Randon Forests", através do uso do pacote de Machine Learning Caret (usado ao longo de todo trabalho inclusive). 

O método consiste nas iterações de vários modelos, a começar pelo pleno, testando várias combinações retirando-se algumas variáveis, e comparando seus poderes explicativos. Por sua vez, o algoritmo de referência para o processo é um dos modelos de classificação mais eficientes da atualidade. (Para mais informacoes sobre os processos disponiveis, checar a documentacao do pacote Caret: http://topepo.github.io/caret/recursive-feature-elimination.html#backwards-selection)

```{r performance}
## Feature Selection

# Carregando pacotes necessarios
library(randomForest)
library(ggplot2)

# Funcao para selecao das variaveis
rfe.feature.selection <- function(num_iters=20, features, target){
  variable_sizes <- 1:10
  control <- rfeControl(functions = rfFuncs, method = "cv", 
                        verbose = FALSE, returnResamp = "all", 
                        number = num_iters)
  rfe_results <- rfe(x = features, y = target, 
                     sizes = variable_sizes, 
                     rfeControl = control)
  return(rfe_results)
}

# Executando a funcao e para obter features mais explicativas
rfe_results <- rfe.feature.selection(features = train_sample[,-21], 
                                 target = train_sample[,21])

# Selecao das Features mais significates e visualizacao da significancia
rfe_results
varImp((rfe_results), scale = F)
optVariables <- rfe_results[["optVariables"]]
plot(rfe_results, type=c("g", "o"))
optVariables

```

O gráfico acima demonstra como o poder explicativo do modelo varia através da inclusão de mais características até chegar ao seu número ótimo. Para ilustrar melhor seu poder explicativo na prática, seguem, abaixo, gráficos entre as váriveis explicativas citadas e nosso alvo.

```{r EDA}
# Plot das variaveis otimas

# Categoricas
plots_cat<- list()
for (i in c('CheckingAcctStat', 'CreditHistory','OtherDetorsGuarantors', 'SavingsBonds', 'Purpose', 
            'Employment')) {
  plots_cat[[i]] <- ggplot(Credit, aes_string(x = i, fill = 'CreditStatus')) + 
  geom_bar(alpha=0.8, colour='black', position = 'dodge') + ggtitle(paste(i, 'x CreditStatus')) +
  theme_minimal()
  print(plots_cat[[i]])
}

# Continua (Duration, CreditAmount, Age)
plots_cont<- list()
for (i in c('Duration', 'CreditAmount')) {
  plots_cont[[i]] <- ggplot(Credit, aes_string(x = 'CreditStatus', y = i, fill = 'CreditStatus')) + 
    geom_boxplot(alpha=0.8, colour='black', position = 'dodge') + ggtitle(paste(i, 'x CreditStatus')) +
    theme_classic()
  print(plots_cont[[i]])
}

```


## Etapa 5 - Criacao do Modelo de Referência
 
Após terminar a análise exploratória, prossegue-se à criação do modelo base: contendo todas as variáveis e sem nenhuma transformação, será usado como referência para os próximos.
 
```{r simples}
## Regressao Classica
SimpleModel <- train(CreditStatus ~ ., data = train_sample, 
                     family = binomial(),
                     method = 'glm',
                     trControl = trainControl(method = 'none'))

# Avaliando o modelo
SimpleModel_pred <-predict(SimpleModel, test_sample)
confusionMatrix(SimpleModel_pred, test_sample$CreditStatus)
```


## Etapa 6 - Execução dos Modelos


Por fim, chega-se à motivação do trabalho: selecionar o modelo com o melhor poder de classificar bons e maus pagadores. Como a amostra de treino não é tão grande, usam-se validações cruzadas repetidas (geradas a partir de bootstrap) para aumentá-la artificialmente. Só serão consideradas as características com maior poder explicativo selecionadas anteriormente para garantir a máxima eficiência. A métrica escolhida foi 'ROC', pois, como o problema é de classificação, ela é mais indicada por usar a taxa entre falsos e verdadeiros positivos.

```{r modelos, results = "hide", warning = FALSE}
# Melhores Variaveis
FS_formula = as.formula(CreditStatus ~ CheckingAcctStat + Duration + OtherDetorsGuarantors +CreditAmount +
  CreditHistory + SavingsBonds + Purpose + Employment)

# Controle dos modelos de treino
train_control <- trainControl(method="repeatedcv", 
                              number=10, 
                              repeats=3, 
                              returnResamp = "all",
                              classProbs = TRUE,
                              summaryFunction = twoClassSummary,
                              verboseIter = TRUE,
                              savePredictions = TRUE)

## Modelos com tratamento

# Glm com melhores variaveis
FSModel <- glmModel_fs <- train(FS_formula, 
                                data = train_sample,
                                method = 'glm',
                                metric = "ROC",
                                trControl = train_control)

## Glmnet

# Grid para escolher melhores hiper parametros
tuning_grid_glm <-  expand.grid(alpha =  c(0, 0.25, 0.75, 1), # indica o peso (0 <- 1) entre L1 e L2
                                lambda = seq(0.0001, 1, length = 5)) # indica o tamanho da penalidade

# Modelo
GlmnetModel <- train(FS_formula, 
                     data = train_sample,
                     metric = "ROC", 
                     method = "glmnet",
                     trControl = train_control,
                     tuneGrid = tuning_grid_glm)

## Random Forest

# Grid para escolher melhores hiper parametros (no caso, so mtry - resto e default)
tuning_grid_rf <- expand.grid(.mtry = c(2, 4, 6, 8),.splitrule = "gini", .min.node.size = 1)

# Modelo
RfModel <- train(FS_formula, 
                 data = train_sample,
                 metric = "ROC", 
                 method = "ranger",
                 trControl = train_control,
                 tuneGrid = tuning_grid_rf)

## KNN

# Grid para escolher melhores hiper parametros (no caso, so mtry - resto e default)
tuning_grid_knn <- expand.grid(.k = 1:25)

# Modelo
KnnModel <- train(FS_formula, 
                  data = train_sample,
                  metric = "ROC", 
                  method = "knn",
                  trControl = train_control,
                  tuneGrid = tuning_grid_knn)
```

Assim como visto acima, foram selecionados 4 algorítmos de classificação muito utilizados: GLM, GLMNET, RF e KNN. O primeiro é o mais simples, sendo o mesmo utilizado para controle; o segundo é uma versão mais sofisticada deste que utiliza as penalidade conhecidas como L1 e L2; o terceiro é o já mencionado "Random Forests"; e o quarto é um "K-Nearest Neighbors", que se baseia em observações similares para se chegar a uma classificação. Nos 3 últimos, por serem mais complexos, pode-se executar a escolha de hiper-parâmetros com o intuito de melhorar ainda mais o desempenho. Para otimizar essa opção, usa-se o recurso "expand.grid" que compara diferentes combinações deles.


## Etapa 7 - Análise dos Resultados

Após o ajustamento dos modelos, faz-se uma comparação da sua métrica utilizada para descobrir qual possui a melhor performance no treino.

```{r dotplot}
# Lista com os modelos
model_list <- list(GLM_FS = FSModel, GLMNET = GlmnetModel, RF = RfModel, KNN = KnnModel)

# Função resamples para compará-los
resamples <- resamples(model_list)

# dotplot
dotplot(resamples, metric = 'ROC')

# Previsao dos melhores
GlmnetModel_pred <-predict(GlmnetModel, test_sample)
FSModel_pred <- predict(FSModel, test_sample)
confusionMatrix(GlmnetModel_pred, test_sample$CreditStatus)
confusionMatrix(FSModel_pred, test_sample$CreditStatus)
```

Como se pode observar acima, os modelos GLM's obtiveram melhor desempenho dentre os outros. Resultado também observado nas suas tabelas de confusão: houve uma melhora na acurácia de 2.48 %, no entanto o mais incrível é constatar como o modelo mais simples possui tanta capacidade. 

Vale ressaltar como há espaço para muitas outras melhorias, como a criação de novas variáveis a partir das originais ou outros algorítmos de classificação, no entanto o objetivo principal do trabalho foi demonstrar como somente uma melhor escolha de variáveis pode, por vezes, ser um fator muito mais relevante para performance do que o uso de modelos super complexos.

## Fim